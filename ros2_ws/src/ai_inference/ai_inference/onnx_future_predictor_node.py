#!/usr/bin/env python3
import rclpy
from rclpy.node import Node
import numpy as np
import onnxruntime as ort
from std_msgs.msg import Float32MultiArray

# =========================
#  CONFIGURATION
# =========================
GRID_SIZE = 256
T_IN = 10
# T_OUT = 10  # ì¶”ë¡  ë…¸ë“œì—ì„  êµ³ì´ ì•ˆ ì¨ë„ ë¨
# POSE_DIM = 3 # ì‚­ì œë¨ (Pose ì•ˆ ì”€)

class OnnxFuturePredictor(Node):
    def __init__(self):
        super().__init__("onnx_future_predictor")

        # ======== 1. ONNX ëª¨ë¸ ë¡œë“œ ========
        # (í•™ìŠµ í›„ ìƒì„±ëœ onnx íŒŒì¼ ê²½ë¡œë¡œ ë§ì¶°ì£¼ì„¸ìš”)
        onnx_path = "/home/ubuntu/ros2_ws/src/ai_inference/new.onnx"
        self.get_logger().info(f"ğŸ“¦ Loading ONNX model: {onnx_path}")

        # Execution Provider ì„¤ì •
        # ë¼ì¦ˆë² ë¦¬íŒŒì´/PC í™˜ê²½ì— ë”°ë¼ CUDAê°€ ì—†ìœ¼ë©´ CPUë¡œ ìë™ ì „í™˜ë¨
        providers = ["CUDAExecutionProvider", "CPUExecutionProvider"]
        
        try:
            self.session = ort.InferenceSession(onnx_path, providers=providers)
        except Exception as e:
            self.get_logger().error(f"Failed to load ONNX: {e}")
            raise e

        self.input_name = self.session.get_inputs()[0].name
        self.output_name = self.session.get_outputs()[0].name

        # ======== 2. Subscriber / Publisher ========
        self.sub = self.create_subscription(
            Float32MultiArray,
            "/bev_pose_sequence", # í† í”½ ì´ë¦„ì€ ìœ ì§€ (bev_bufferì™€ ì—°ê²°)
            self.on_bev_sequence,
            10
        )

        self.pub = self.create_publisher(
            Float32MultiArray,
            "/future_occupancy",
            10
        )

        self.get_logger().info("ğŸ”® ONNX Future Predictor Node Started (No Warping).")


    def on_bev_sequence(self, msg: Float32MultiArray):
        """
        Warping ì—†ì´ ë“¤ì–´ì˜¨ BEV ì‹œí€€ìŠ¤ë¥¼ ë°”ë¡œ ì¶”ë¡ 
        """
        # 1. ë°ì´í„° ë°›ê¸°
        seq_flat = np.array(msg.data, dtype=np.float32)

        # ë°ì´í„° í¬ê¸° ê²€ì¦
        expected_size = T_IN * GRID_SIZE * GRID_SIZE
        if seq_flat.size != expected_size:
            self.get_logger().warn(f"âš  Wrong sequence size. Expected {expected_size}, Got {seq_flat.size}")
            return

        # 2. Reshape & Batch Dimension ì¶”ê°€
        # Flat -> (10, 256, 256) -> (1, 10, 256, 256)
        # Pose ë°ì´í„° ë¶„ë¦¬ë‚˜ Warping ê³¼ì •ì´ ì‹¹ ì‚¬ë¼ì§
        bev_input = seq_flat.reshape(1, T_IN, GRID_SIZE, GRID_SIZE)

        # 3. ONNX ì¶”ë¡ 
        try:
            outputs = self.session.run(
                [self.output_name],
                {self.input_name: bev_input}
            )
            
            # outputs[0] shape: (1, 10, 256, 256)
            future_logits = outputs[0]

            # 4. Sigmoid (Logits -> Probability)
            # 0~1 ì‚¬ì´ í™•ë¥ ê°’ìœ¼ë¡œ ë³€í™˜
            future_occ = 1 / (1 + np.exp(-future_logits))

            # 5. ê²°ê³¼ ë°œí–‰
            out_msg = Float32MultiArray()
            out_msg.data = future_occ.flatten().tolist()
            self.pub.publish(out_msg)

        except Exception as e:
            self.get_logger().error(f"Inference Error: {e}")


def main(args=None):
    rclpy.init(args=args)
    node = OnnxFuturePredictor()
    rclpy.spin(node)
    node.destroy_node()
    rclpy.shutdown()


if __name__ == "__main__":
    main()